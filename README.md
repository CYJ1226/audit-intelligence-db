# Audit Intelligence Database (A.I.D)
신입 감사원의 역량 강화와 전문 감사원의 업무 효율화를 위한 감사 정보 통합 서비스 Audit Intelligence Database (A.I.D) 입니다. RAG 기반의 유사 감사 사례 검색부터 AI Agent를 활용한 보고서 초안 작성, 트렌드 분석 대시보드까지, 감사의 전 과정을 스마트하게 지원합니다.

시스템 시연 영상은 [A.I.D 시연 영상](https://www.youtube.com/watch?v=5OOfkYR8HvY)에서 확인할 수 있습니다.

## 1. Overview
감사 업무는 방대한 규정과 과거 사례를 기반으로 의사결정을 내려야 하는 특성상, 실무자가 관련 문서를 빠르게 탐색하고 종합하는 과정에서 상당한 시간과 노력이 소요됩니다. 특히 신입 실무자의 경우 규정과 선례에 대한 숙련도가 낮아 반복적인 확인 작업이 필요하고, 이는 업무 효율 저하와 판단 부담으로 이어집니다.

단순한 유사 사례 검색을 넘어 감사 보고서 초안 작성, 그리고 주요 지표를 시각화한 대시보드까지 통합적으로 지원하는 시스템이 있다면 감사 업무 전반의 생산성과 일관성을 크게 향상시킬 수 있을 것이라고 판단했습니다.

이에 본 프로젝트에서는 과거 감사 사례를 기반으로, 실무자의 정보 탐색을 자동화하고 의사결정을 보조하며, 나아가 보고서 작성과 결과 시각화까지 지원하는 AI 감사 업무 보조 시스템을 설계하고 구현하는 것을 목표로 합니다.

단순 구축을 넘어 Opik 기반의 실시간 모니터링과 Ragas를 활용한 정량적 성능 지표 관리를 통해 지속적으로 답변의 정확도를 최적화하는 RAG 파이프라인을 지향합니다.

## 2. Features
- 규정 및 감사 사례 통합 검색
    - 단순 유사 사례 검색뿐만 아니라, 처분 수준 추천, 특정 처분을 받았던 사례, 위반 규정 등 다양한 질문 유형에 대해 맞춤형 답변을 제공합니다.
    - 사건 유형, 조치 결과, 판단 근거, 출처 등을 함께 제공하여 실무자의 의사결정을 위한 참고 자료로 활용할 수 있습니다.

- 감사 보고서 초안 자동 생성
    - 사용자가 제공한 기본 정보와 검색된 사례를 기반으로, 주요 사실 요약, 문제 상황 정리, 참고 규정 및 사례 인용을 포함한 감사 보고서 초안을 자동으로 생성합니다.
    - 정보 수집 → 관련 사례 검색 → 보고서 초안 작성의 3단계로 구성되며, 실무자는 생성된 초안을 검토, 수정하는 방식으로 보고서 작성 시간을 단축할 수 있습니다.
    - Agent가 사용자와 대화하며 단계적으로 정보를 보완하여 완성도 높은 초안을 생성합니다.
    - 완성된 보고서는 hwp / docx 파일 형태로 다운로드할 수 있습니다.

- 감사 지표 대시보드 시각화
    - 감사 결과 데이터를 기반으로 주요 지표를 대시보드 형태로 시각화합니다.
    - 보고서 수집 현황, 조치 사항 분석, 키워드 분석 등을 한 눈에 파악할 수 있도록 하였습니다.

- Opik 기반 실시간 모니터링
    - RAG 파이프라인의 Trace 기능을 통해 데이터 흐름을 실시간 모니터링
    - 사용자 질문과 모델 답변 간의 비용, 지연 시간, 에러 여부를 관리

- LLM Judge를 활용한 정량적 성능 평가
    - Few-shot 기법을 적용한 문제 생성 RAG를 사용하여 약 100개의 테스트 질문 생성
    - Ragas의 Faithfulness와 Opik의 Hallucination을 활용하여 context를 기반으로 답변을 했는지 평가
    - Ragas의 Answer Relevancy와 Opik의 Answer Relevance를 활용하여 답변과 질문 간의 연관성 파악

- 통합 AI 감사 업무 보조 환경
    - 유사 사례 검색, 보고서 작성, 대시보드 분석을 하나로 통합한 업무 환경을 제공합니다.
    - 단순 정보 검색 도구를 넘어, 감사 업무 전반의 의사결정 과정을 보조하는 시스템을 목표로 합니다.
    - 신입과 숙련자 간 업무 숙련도 차이를 완화하고, 감사 품질의 일관성을 확보하는 데 기여합니다.

## 3. Data Pipeline (Team)
※ 본 Data Pipeline은 팀에서 설계·구현한 영역이며, 본인은 해당 파이프라인을 기반으로 AI/RAG 레이어를 구축하였습니다.

- 다중 소스 데이터 수집
    - 감사원: 공식 API를 활용한 정형 데이터 및 보고서 원문 수집
    - ALIO: API 미제공 항목에 대해 Selenium 기반 멀티스레딩 크롤러 구축
    - Rate Limit 대응을 위한 지연 시간 설정 및 실패 시 재시도(3회) 로직 구현
- 문서 파싱 및 표준화
    - 분석 품질 일원화를 위해 hwp파일을 pdf로 일괄 변환
    - Marker-pdf를 활용하여 비정형 pdf를 Markdown 형식으로 변환
- 지능형 전처리 및 분할
    - 보고서 초반 정보를 분석하여 문서 전체 속성을 나타내는 메타데이터 추출
    - LLM이 헤더 구조를 분석하여 논리적 사례 단위로 구역을 나누는 계층적 분할 수행
    - 복잡한 내용 해석을 위해 고성능 추론 모델인 gpt-5.1 활용
- 고차원 벡터화
    - 타 모델 대비 고차원 벡터 표현이 가능하여, 유사한 유형의 감사 사례 간의 미세한 문맥적 차이를 정밀하게 식별 가능
- PostgreSQL 기반 하이브리드 검색 엔진
    - RDB의 강점을 살린 핵심 키워드 매칭과 벡터 유사도 검색을 결합
    - 질문 내 주요 키워드가 포함된 사례를 우선순위로 배치하여 노이즈 데이터를 제거하고, 검색 결과가 부족할 경우 벡터 검색으로 보완하여 답변의 품질 확보

## 4. System Architecture
본 프로젝트는 감사 업무를 지원하기 위한 RAG 기반의 AI 시스템으로 감사 사례 수집부터 전처리, 검색, 추론, 평가까지 전 과정을 자동화하는 것을 목표로 합니다.
시스템은 팀 단위로 전체 아키텍처를 설계하였으며, 그 중 본인은 LLM 기반 AI 파이프라인과 RAG/Agent 로직을 중심으로 담당하였습니다.

### 1. Data Ingestion & Preprocessing (Team)
감사 사례 및 규정 데이터는 팀에서 구축한 데이터 파이프라인을 통해 수집·전처리됩니다. 외부 공공 데이터(API 및 웹 크롤링)로부터 수집된 문서는 HWP → PDF → Markdown 변환 과정을 거쳐 구조화되며, 이후 AI 파이프라인에서 활용 가능한 형태로 Database에 저장됩니다.

### 2. AI Pipeline & RAG Core (My Contribution)
- LLM을 활용하여 사용자 질문에서 검색용 쿼리문을 생성하고, 이를 기반으로 PostgreSQL에서 키워드 중심의 1차 검색을 수행한 뒤, 검색 결과가 부족한 경우 pgvector를 활용한 벡터 유사도 검색으로 보완하는 하이브리드 검색 구현
- 단일 질의 기반 검색에서는 질문 표현에 따라 검색 결과 편차가 커, 사용자의 자연어 질문을 분석하여 검색 성능 향상을 위해 LLM 기반 Multi-query로 의미 공간 확장
- 초기에는 단순 벡터 검색만 사용하여 질문 의도와 무관한 문서가 상위에 노출되는 문제가 있었고, 이로 인해 답변의 신뢰도가 낮아지는 문제가 발생. 이를 해결하기 위해 Reranking 구조를 도입하였으며, 그 결과 Top-k 검색 결과 내 정답 문서 포함률을 유의미하게 개선

### 3. Agent 기반 보고서 생성 (My Contribution)
- 단순 질의응답을 넘어, 감사 보고서 초안 작성을 지원하기 위해 Agent 아키텍처 설계
- 사용자로부터 사건 개요 및 핵심 정보 수집, 관련 사례 자동 검색, 검색 결과와 입력 정보를 종합하여 주요 사실 요약, 문제 상황 정리, 참고 규정 및 유사 사례 인용하여 최종 감사 보고서 초안 자동 생성
- 결과는 hwp / docx 파일로 다운로드 가능

### 4. Evaluation & Observability (My Contribution)
- RAG 시스템의 신뢰성과 품질을 확보하기 위해 실험 기반 평가 및 모니터링 환경을 구축
-  Opik을 Docker 환경에 구성하여 질문, 답변, context, 비용, 지연 시간, 에러 등을 관리
- 테스트 질문에 대해 Ragas와 Opik 자체 지표를 활용하여 Faithfulness, Hallucination, Answer Relevancy, Answer Relevance 등 RAG 성능을 정량적으로 평가
- gpt-4.1-mini를 Judge 모델로 활용하여 평가 체계 구축

### 5. Presentation Layer (Team)
Streamlit 기반 웹 UI를 통해 다음 기능을 제공합니다.
- 질의응답
- 보고서 생성
- 감사 지표 대시보드

## 5. Team Collaboration
- 본 프로젝트는 4인 팀으로 진행되었습니다.
- 데이터 수집 및 대시보드 구축은 팀원이 담당하였습니다.
- 본인은 다음 영역을 주도적으로 담당하였습니다:
    - RAG 시스템 아키텍처 설계
    - 감사 보고서 작성 Agent 설계
    - 결과 모니터링 및 LLM Judge 평가 진행

## 6. Tech Stack
### My Contribution
- Python
- Langflow (RAG 파이프라인 및 Agent 구축)
- Docker (Opik 로컬 호스팅)
- Reranker (재순위화)
- OpenAI 
    - gpt-4o-mini: Multi-query 생성
    - gpt-4.1: 사용자 질문 의미 해석 및 검색용 핵심 키워드 추출
    - gpt-5.1: 최종 답변 생성
    - gpt-4.1-mini: Judge 모델 (평가)
- Opik (실험 로그 및 평가 관리)
- Ragas (RAG 성능 평가)

### Team Stack
- n8n (Data pipeline)
- FastAPI (Backend API)
- OpenAI
    - text-embedding-3-large: 문서 임베딩
    - gpt-5.1: 데이터 전처리 및 정제x`
- PostgreSQL (Database)
- Streamlit (Frontend UI)

## 7. Lessons Learned
- RAG 답변이 단순 문서 요약에 머무르는 문제를 해결하기 위해, 처분 수준 추천 및 판단 근거 종합 등 프롬프트 구조를 개선하였으며, 이를 통해 단순 정보 제공형 시스템에서 의사결정 지원형 시스템으로 성격을 전환할 수 있었습니다.
- 시스템 고도화 이후, 정성적 평가(사람 기준)에서는 답변의 논리 구조와 가독성이 명확히 개선되었으나, 일부 정량 지표는 고도화 이전 모델이 근소하게 높게 측정되는 현상이 발생하였습니다.
    - 지표의 보수성: Ragas 지표는 원문 컨텍스트와의 단어/문장 유사도에 민감하게 반응하며, 추론을 통해 답변을 재구성할수록 오히려 점수가 하락하는 경향이 존재
    - LLM-as-a-Judge의 한계: 평가 모델이 논리적 추론의 깊이보다 원문 키워드의 직접적 포함 여부를 더 중요하게 판단하는 편향 가능성을 확인
    - 이를 통해, 자동화된 정량 지표는 시스템 변화 추이를 관찰하는 보조 지표로는 유효하지만, 실제 서비스 품질 평가는 Human-in-the-loop 기반 정성 평가와 병행되어야 함을 경험적으로 확인하였습니다.
    - 실제 RAG 버전별 실험(experiments의 score.md, score_graph.png)에서도, 사람 기준 답변 품질은 지속적으로 개선되었으나, 정량 지표는 Answer Relevancy를 제외하고는 대체로 유지 또는 소폭 감소하는 양상을 보이고 있습니다.
- PostgreSQL 기반 하이브리드 검색 구조를 통해, 단순 벡터 검색 대비 정확한 키워드 매칭과 의미 기반 검색의 장점을 동시에 활용할 수 있었으며, 이는 검색 신뢰도 측면에서 효과적인 접근임을 확인하였습니다.
- 한국어 특화 모델(HyperClova 등)도 실험해보았으나, 전반적인 임베딩 품질과 추론 안정성 측면에서는 여전히 OpenAI 계열 모델이 가장 일관된 성능을 보였습니다.